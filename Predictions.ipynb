{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes how to generate predictions of labels for a determined dataset, from a model containing the neural network weights.\n",
    "\n",
    "# Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barimpac/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RetinaNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/barimpac/anaconda3/lib/python3.6/site-packages/keras/models.py:274: UserWarning: Output \"nms\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"nms\" during training.\n",
      "  sample_weight_mode=sample_weight_mode)\n"
     ]
    }
   ],
   "source": [
    "# adjust this to point to your downloaded/trained model\n",
    "model_path = os.path.join('/home/barimpac/keras-retinanet/snapshots/old_2', 'resnet50_csv_50.h5')\n",
    "\n",
    "# load retinanet model\n",
    "model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "#print(model.summary())\n",
    "\n",
    "# load label to names mapping for visualization purposes\n",
    "labels_to_names = {0: 'defect'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store image names and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path of the directory containing the images that you would like to label.\n",
    "# Make sure you have only images in this directory\"\n",
    "d = '/home/barimpac/keras-retinanet/data/imgs/test/'\n",
    "\n",
    "images = os.listdir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:  1.8735449314117432\n",
      "processing time:  1.2867965698242188\n",
      "processing time:  1.4992785453796387\n",
      "processing time:  0.9653220176696777\n",
      "processing time:  1.328805923461914\n",
      "processing time:  1.5543527603149414\n",
      "processing time:  1.188965082168579\n",
      "processing time:  1.4571928977966309\n",
      "processing time:  1.6101233959197998\n",
      "processing time:  1.1563506126403809\n",
      "processing time:  1.414827823638916\n",
      "processing time:  1.5007376670837402\n",
      "processing time:  1.1251506805419922\n",
      "processing time:  1.6065592765808105\n",
      "processing time:  1.450901746749878\n",
      "processing time:  1.1128466129302979\n",
      "processing time:  1.646498441696167\n",
      "processing time:  1.3393757343292236\n",
      "processing time:  1.2754936218261719\n",
      "processing time:  1.5909039974212646\n",
      "processing time:  1.367602825164795\n",
      "processing time:  1.3895187377929688\n",
      "processing time:  1.6230723857879639\n",
      "processing time:  1.1576652526855469\n",
      "processing time:  1.4360978603363037\n",
      "processing time:  1.672267198562622\n",
      "processing time:  1.079819917678833\n",
      "processing time:  1.4026811122894287\n",
      "processing time:  1.6676945686340332\n",
      "processing time:  1.1090989112854004\n",
      "processing time:  1.3257057666778564\n",
      "processing time:  1.6490118503570557\n",
      "processing time:  1.2064027786254883\n",
      "processing time:  1.3754327297210693\n",
      "processing time:  1.566983699798584\n",
      "processing time:  1.1506762504577637\n",
      "processing time:  1.5228023529052734\n",
      "processing time:  1.5786192417144775\n",
      "processing time:  1.07273268699646\n",
      "processing time:  1.3921105861663818\n",
      "processing time:  1.4965507984161377\n",
      "processing time:  1.1121282577514648\n",
      "processing time:  1.4288735389709473\n",
      "processing time:  1.591629981994629\n",
      "processing time:  1.0698473453521729\n",
      "processing time:  1.3379082679748535\n",
      "processing time:  1.5849251747131348\n",
      "processing time:  1.0992395877838135\n",
      "processing time:  1.337235450744629\n",
      "processing time:  1.7044076919555664\n",
      "processing time:  1.15535569190979\n",
      "processing time:  1.3408489227294922\n",
      "processing time:  1.6771924495697021\n",
      "processing time:  1.111680269241333\n",
      "processing time:  1.4624593257904053\n",
      "processing time:  1.6831915378570557\n",
      "processing time:  1.077077865600586\n",
      "processing time:  1.4560225009918213\n",
      "processing time:  1.435760498046875\n",
      "processing time:  1.1689958572387695\n",
      "processing time:  1.484644889831543\n",
      "processing time:  1.4718120098114014\n",
      "processing time:  1.1064321994781494\n",
      "processing time:  1.5200250148773193\n",
      "processing time:  1.4230735301971436\n",
      "processing time:  1.0682787895202637\n",
      "processing time:  1.36094331741333\n",
      "processing time:  1.7419443130493164\n",
      "processing time:  1.137193202972412\n",
      "processing time:  1.4313020706176758\n",
      "processing time:  1.568159818649292\n",
      "processing time:  1.0534400939941406\n",
      "processing time:  1.377575159072876\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for image in images:\n",
    "    # load image\n",
    "    img_name = image\n",
    "    image = read_image_bgr(d+image)\n",
    "    \n",
    "# preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "# process image\n",
    "    start = time.time()\n",
    "    _, _, detections = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    print(\"processing time: \", time.time() - start)\n",
    "\n",
    "# compute predicted labels and scores\n",
    "    predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\n",
    "#print(predicted_labels)\n",
    "    scores = detections[0, np.arange(detections.shape[1]), 4 + predicted_labels]\n",
    "#print(scores)\n",
    "\n",
    "# correct for image scale\n",
    "    detections[0, :, :4] /= scale\n",
    "#print(detections)\n",
    "\n",
    "# visualize detections\n",
    "    for idx, (label, score) in enumerate(zip(predicted_labels, scores)):\n",
    "        if score < 0.5:\n",
    "            #print(\"t\")\n",
    "            continue\n",
    "        b = detections[0, idx, :4].astype(int)\n",
    "        labels.append([img_name, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(labels, columns=['image', 'defect coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name of the file to save the predictions\n",
    "df.to_csv(\"test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
